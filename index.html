<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <title>Nihei Fumio</title> <!-- そうやってソース見て... -->

    <!-- UIkit CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/uikit@3.8.0/dist/css/uikit.min.css" />
    <!-- UIkit JS -->
    <script src="https://cdn.jsdelivr.net/npm/uikit@3.8.0/dist/js/uikit.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/uikit@3.8.0/dist/js/uikit-icons.min.js"></script>
</head>

<body>

    <div class="uk-padding uk-section-small uk-section-primary">
        <h2> 二瓶 芙巳雄 (NIHEI Fumio)</h2>
        <div class="uk-text-left" uk-grid>
            <!-- <div class="uk-width-small"> <img data-src=./resource/portrait.png alt="" uk-img> </div> -->
            <div class="uk-width-expand@m">
                <p>NTT 人間情報研究所 ポスドク研究員</p>
                <p>博士（理工学）</p>
                <p>Contact: 掲載保留</p>
            </div>
        </div>
    </div>


    <div class="uk-padding">
        <h2>研究業績</h2>
        <!-- citation styleをACM longなんとかにしてformatted citetionコピーすること！ -->
        <!-- citation styleをACM longなんとかにしてformatted citetionコピーすること！ -->
        <!-- citation styleをACM longなんとかにしてformatted citetionコピーすること！ -->

        <h3 class="uk-heading-bullet"> 学術論文</h3> <!-- <ol class="uk-list uk-list-bullet"> -->
        <ol reversed>
            <li>中野有紀子, 大山真央, 二瓶芙巳雄, 東中竜一郎 and 石井亮 2021. 性格特性を表現するエージェントジェスチャの生成. ヒューマンインタフェース学会論文誌. 23, 2 (2021), 153–164. DOI:https://doi.org/10.11184/his.23.2_153.</li>
            <li>二瓶芙巳雄, 田口和佳奈, 中野有紀子, 深澤伸一 and 赤津裕子 2021. 多人数遠隔コミュニケーションにおける肯定的感情表出支援の効果と支援適用タイミングの決定. 情報処理学会論文誌. 62, 2 (Feb. 2021), 761–771.</li>
            <li>二瓶芙巳雄 and 中野有紀子 2020. マルチモーダル情報に基づく重要発言推定モデルを搭載した議論要約ブラウザの有効性の検証. ヒューマンインタフェース学会論文誌. 22, 2 (2020), 137–150. DOI:https://doi.org/10.11184/his.22.2_137.</li>
            <li>Nihei, F. and Nakano, Y.I. 2019. Exploring Methods for Predicting Important Utterances Contributing to Meeting Summarization. Multimodal Technologies and Interaction. 3, 3 (2019). DOI:https://doi.org/10.3390/mti3030050.</li>
            <li>二瓶芙巳雄, 中野有紀子 and 高瀬裕 2019. 言語・非言語情報に基づく議論要約のための重要発言推定. 電子情報通信学会論文誌 A. J102-A, No.2 (2019), pp.35-47.</li>
            <li>二瓶芙巳雄, 高瀬裕 and 中野有紀子 2017. 非言語情報に基づくグループ議論における重要発言の推定―グループ議論の要約生成に向けて―. 電子情報通信学会論文誌 A. Vol.J100-A, No.1 (2017), pp.34-44.</li>
            <li>林佑樹, 二瓶芙巳雄, 中野有紀子, 黄宏軒 and 岡田将吾 2015. グループディスカッションコーパスの構築および性格特性との関連性の分析. 情報処理学会論文誌. 56, 4 (2015), 1217–1227.</li>
        </ol>
        <h3 class="uk-heading-bullet"> 国際会議・ワークショップ（査読あり）</h3>
        <ol reversed>
            <li>Nihei, F., Ishii, R., Nakano, Y.I., Fukayama, A. and Nakamura, T. 2022. Dialogue Acts Aided Important Utterance Detection Based on Multiparty and Multimodal Information. INTERSPEECH 2022 (accepted)</li>
            <li>Ito, A., Nakano, Y.I., Nihei, F., Sakato, T., Ishii, R., Fukayama, A. and Nakamura, T. 2022. Predicting Persuasiveness of Participants in Multiparty Conversations. 27th International Conference on Intelligent User Interfaces (New York, NY, USA, 2022), 85–88.</li>
            <li>Nihei, F. and Nakano, Y.I. 2021. Web-ECA: A Web-Based ECA Platform. Proceedings of the 2021 International Conference on Multimodal Interaction (New York, NY, USA, 2021), 835–836.</li>
            <li>Ueno, R., Nakano, Y.I., Zeng, J. and Nihei, F. 2020. Estimating the Intensity of Facial Expressions Accompanying Feedback Responses in Multiparty Video-Mediated Communication. Proceedings of the 2020 International Conference on Multimodal Interaction (New York, NY, USA, 2020), 144–152.</li>
            <li>Nihei, F. and Nakano, Y.I. 2020. A Multimodal Meeting Browser That Implements an Important Utterance Detection Model Based on Multimodal Information. Proceedings of the 25th International Conference on Intelligent User Interfaces Companion (New York, NY, USA, 2020), 59–60.</li>
            <li>Nihei, F., Nakano, Y., Higashinaka, R. and Ishii, R. 2019. Determining Iconic Gesture Forms Based on Entity Image Representation. 2019 International Conference on Multimodal Interaction (New York, NY, USA, 2019), 419–425.</li>
            <li>Fukasawa, S., Akatsu, H., Taguchi, W., Nihei, F. and Nakano, Y. 2019. Correction to: Presenting Low-Accuracy Information of Emotion Recognition Enhances Human Awareness Performance. Human Interface and the Management of Information. Visual Information and Knowledge Management: Thematic Area, HIMI 2019, Held as Part of the 21st HCI International Conference, HCII 2019, Orlando, FL, USA, July 26–31, 2019, Proceedings, Part I (Berlin, Heidelberg, 2019), C1.</li>
            <li>Fukasawa, S., Akatsu, H., Taguchi, W., Nihei, F. and Nakano, Y. 2019. Presenting Low-Accuracy Information of Emotion Recognition Enhances Human Awareness Performance. Human Interface and the Management of Information. Visual Information and Knowledge Management (Cham, 2019), 415–424.</li>
            <li>Nihei, F. and Nakano, Y.I. 2019. Exploring Methods for Predicting Important Utterances Contributing to Meeting Summarization. Multimodal Technologies and Interaction. 3, 3 (2019). DOI:https://doi.org/10.3390/mti3030050.</li>
            <li>Taguchi, W., Nihei, F., Takase, Y., Nakano, Y.I., Fukasawa, S. and Akatsu, H. 2018. Effects of Face and Voice Deformation on Participant Emotion in Video-mediated Communication. Proceedings of the 20th International Conference on Multimodal Interaction: Adjunct (New York, NY, USA, 2018), 8:1--8:5.</li>
            <li>Nihei, F., Nakano, Y.I. and Takase, Y. 2018. Fusing Verbal and Nonverbal Information for Extractive Meeting Summarization. Proceedings of the Group Interaction Frontiers in Technology (New York, NY, USA, 2018), 9:1--9:9.</li>
            <li>Tomiyama, K., Nihei, F., Nakano, Y.I. and Takase, Y. 2018. Identifying discourse boundaries in group discussions using a multimodal embedding space. CEUR Workshop Proceedings (2018).</li>
            <li>Nihei, F., Nakano, Y.I. and Takase, Y. 2017. Predicting Meeting Extracts in Group Discussions Using Multimodal Convolutional Neural Networks. Proceedings of the 19th ACM International Conference on Multimodal Interaction (New York, NY, USA, 2017), 421–425.</li>
            <li>Vrzakova, H., Bednarik, R., Nakano, Y.I. and Nihei, F. 2016. Speakers’ head and gaze dynamics weakly correlate in group conversation. Eye Tracking Research and Applications Symposium (ETRA) (2016).</li>
            <li>Nihei, F., Nakano, Y.I. and Takase, Y. 2016. Meeting Extracts for Discussion Summarization Based on Multimodal Nonverbal Information. Proceedings of the 18th ACM International Conference on Multimodal Interaction (New York, NY, USA, 2016), 185–192.</li>
            <li>Vrzakova, H., Bednarik, R., Nakano, Y. and Nihei, F. 2014. Influential statements and gaze for persuasion modeling. Proceedings of the 8th Nordic Conference on Human-Computer Interaction Fun, Fast, Foundational - NordiCHI ’14 (New York, New York, USA, 2014), 915–918.</li>
            <li>Nihei, F., Nakano, Y.I., Hayashi, Y., Hung, H.-H. and Okada, S. 2014. Predicting Influential Statements in Group Discussions Using Speech and Head Motion Information. Proceedings of the 16th International Conference on Multimodal Interaction (New York, NY, USA, 2014), 136–143.</li>

        </ol>
        <h3 class="uk-heading-bullet"> 国内会議（研究会・全国大会）</h3>
        <ol reversed>
            <!-- <li>伊藤君の説得力の研究忘れずに！</li> -->
            <li>二瓶芙巳雄, 中野有紀子, 東中竜一郎 and 石井亮 2020. 対象物のイメージに基づく図像的ジェスチャの形状推定. FIT2020 第19回情報科学技術フォーラム (2020).<span class="uk-label">FIT論文賞</span></li>
            <li>田口和佳奈, 中野有紀子, 二瓶芙巳雄, 深澤伸一 and 赤津裕子 2020. 音声・表情の非言語シグナルに基づく多人数遠隔コミュニケーション支援方法. 2020年度人工知能学会全国大会 (2020).</li>
            <li>二瓶芙巳雄 and 中野有紀子 2020. マルチモーダル情報に基づく重要発言推定モデルを搭載したマルチモーダル議論要約ブラウザの評価. 2020年度人工知能学会全国大会 (2020).</li>
            <li>冨山健, 二瓶芙巳雄, 高瀬裕 and 中野有紀子 2019. マルチモーダル特徴量を用いた談話セグメントの検出. 2019年度人工知能学会全国大会 (2019).</li>
            <li>二瓶芙巳雄, 中野有紀子 and 高瀬裕 2018. 言語・非言語情報の融合に基づく重要発言の推定. 2018年度人工知能学会全国大会 (2018).<span class="uk-label">大会優秀賞</span></li>
            <li>二瓶芙巳雄, 中野有紀子 and 高瀬裕 2017. マルチモーダルCNNを用いた議論要約のための会話の抜粋. 電子情報通信学会技術研究報告. 117, 177 (2017), 55–59.</li>
            <li>二瓶芙巳雄, 林佑樹 and 中野有紀子 2016. 意思決定型議論における非言語情報に基づく重要発言の推定. 2016年度人工知能学会全国大会 (2016).</li>
            <li>二瓶芙巳雄, 中野有紀子 and 高瀬裕 2016. マルチモーダル非言語情報に基づく議論要約のための会話抜粋. HCGシンポジウム2016 (2016).</li>
            <li>二瓶芙巳雄, 中野有紀子, 林佑樹, 黄宏軒 and 岡田将吾 2015. 発話情報と頭部移動情報に基づく議論における影響力のある発言の予測. 情報処理学会全国大会 (2015).</li>
            <li>二瓶芙巳雄, 林佑樹 and 中野有紀子 2014. グループディスカッションにおける議論状態の変化の検出. 2014年度人工知能学会全国大会 (2014), 4B1-2.<span class="uk-label">大会優秀賞</span></li>
            <li>二瓶芙巳雄, 菅野建, 林佑樹 and 中野有紀子 2013. 発話の韻律的特徴による性格印象の評定 －面接支援エージェントを目指して－. ヒューマンインタフェースシンポジウム2013 (2013), 683–688.</li>
        </ol>
    </div>

    <div class="uk-padding">
        <h2>職歴 / 学歴</h2>
        <ul class="uk-list uk-list-hyphen uk-list-collapse">
            <li> 2021/10 - 現在: NTT人間情報研究所ポスドク研究員 </li>
            <li> 2019/04: 成蹊大学特別共同研究員 </li>
            <li> 2019/03: 成蹊大学理工学研究科博士後期過程 修了</li>
            <li> 2016/03: 成蹊大学理工学研究科博士前期過程 修了</li>
            <li> 2014/03: 成蹊大学理工学部情報科学科 卒業</li>
        </ul>
    </div>

    <div class="uk-padding">
        <h2>その他</h2>

        <h3 class="uk-heading-bullet">経験技術</h3>
        <!-- やったことを忘れないようにしないと... -->
        <!-- やったことがあるだけで得意とは言っていない -->
        C# / 機械学習 / 深層学習 / Python / Docker / Unity / javascript / node.js / Java / Google Cloud Platform

        <h3 class="uk-heading-bullet">著者紹介文</h3>
        <!-- 論文に載せるやつ．どれが最新かわかんなくなるのでここで管理． -->
        2016年成蹊大学大学院理工学研究科修士課程修了．2019年同大学院博士課程修了．
        成蹊大学特別共同研究員を経て，現在，NTT人間情報研究所ポスドク研究員．
        マルチモーダル情報に基づくグループ会議の分析とモデル化の研究に従事．
        人工知能学会，情報処理学会各会員．博士（理工学）．
    </div>

</body>

</html>